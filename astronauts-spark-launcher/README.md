# üöÄ Astronauts Spark Launcher

Projeto que demonstra como executar jobs Spark via API FastAPI usando Kubernetes e Spark Operator.

## üìÅ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ launcher/                    # API FastAPI para lan√ßar jobs Spark
‚îÇ   ‚îú‚îÄ‚îÄ api/                     # C√≥digo da API
‚îÇ   ‚îú‚îÄ‚îÄ k8s/                     # Manifests K8s da API
‚îÇ   ‚îú‚îÄ‚îÄ manifests/               # Templates dos jobs Spark
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Dockerfile da API
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt         # Depend√™ncias Python da API
‚îú‚îÄ‚îÄ jobs/                        # Jobs Spark
‚îÇ   ‚îú‚îÄ‚îÄ astronauts.py           # Script que busca astronautas no espa√ßo
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Dockerfile para jobs Spark
‚îÇ   ‚îî‚îÄ‚îÄ spark-requirements.txt  # Depend√™ncias Python dos jobs
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

## üéØ Conceitos Fundamentais

### SparkApplication vs Driver vs Executor

#### üß† **SparkApplication**
√â um **recurso customizado do Kubernetes** (CRD) criado pelo Spark Operator que representa um job Spark completo.

- **Fun√ß√£o**: Gerencia todo o ciclo de vida de um job Spark
- **Analogia**: √â como uma "receita" que diz ao Kubernetes como executar seu job Spark
- **Responsabilidades**:
  - Criar pods para Driver e Executors
  - Gerenciar configura√ß√µes de recursos
  - Monitorar status da execu√ß√£o
  - Fazer cleanup ap√≥s conclus√£o

#### üöó **Driver** 
√â o **c√©rebro** do job Spark - coordena toda a execu√ß√£o.

- **Fun√ß√£o**: Coordenador principal que gerencia a execu√ß√£o
- **Onde roda**: Em um pod separado no Kubernetes (`spark-astronauts-XXXXXX-driver`)
- **Responsabilidades**:
  - Criar o `SparkContext`
  - Dividir o trabalho em tarefas
  - Distribuir tarefas para os Executors
  - Coletar resultados
  - Exibir logs principais

#### ‚ö° **Executor**
S√£o os **trabalhadores** que executam as tarefas distribu√≠das.

- **Fun√ß√£o**: Processam os dados em paralelo
- **Onde roda**: Em pods separados (`spark-astronauts-XXXXXX-exec-X`)
- **Responsabilidades**:
  - Executar tarefas recebidas do Driver
  - Armazenar dados em cache se necess√°rio
  - Enviar resultados de volta ao Driver

### üìä Fluxo de Execu√ß√£o

```mermaid
graph TD
    A[SparkApplication YAML] --> B[Spark Operator]
    B --> C[Cria Driver Pod]
    C --> D[Driver inicia SparkContext]
    D --> E[Driver solicita Executors]
    E --> F[Operator cria Executor Pods]
    F --> G[Driver distribui tarefas]
    G --> H[Executors processam dados]
    H --> I[Resultados voltam ao Driver]
    I --> J[Job finaliza]
    J --> K[Pods s√£o removidos]
```

## üìã Documenta√ß√£o do SparkApplication YAML

### Estrutura B√°sica

```yaml
apiVersion: sparkoperator.k8s.io/v1beta2  # Vers√£o da API do Spark Operator
kind: SparkApplication                     # Tipo de recurso Kubernetes
metadata:
  name: spark-astronauts                   # Nome √∫nico do job (ser√° substitu√≠do por timestamp)
  namespace: default                       # Namespace onde o job ser√° executado
spec:
  # Configura√ß√µes do job aqui...
```

### Configura√ß√µes do Job

```yaml
spec:
  type: Python                    # Tipo de aplica√ß√£o Spark
                                 # Op√ß√µes: Java, Scala, Python, R
  
  pythonVersion: "3"             # Vers√£o do Python (apenas para type: Python)
                                 # Op√ß√µes: "2", "3"
  
  mode: cluster                  # Modo de execu√ß√£o
                                 # cluster: Driver roda no cluster K8s
                                 # client: Driver roda fora do cluster (n√£o recomendado)
  
  image: docker.io/gmaas2/spark-astronauts-jobs:1.0  # Imagem Docker com Spark + c√≥digo
  
  imagePullPolicy: Always        # Pol√≠tica de pull da imagem
                                 # Always: Sempre faz pull
                                 # IfNotPresent: Pull apenas se n√£o existir localmente
                                 # Never: Nunca faz pull
  
  mainApplicationFile: local:///opt/spark/jobs/astronauts.py  # Arquivo principal
                                 # local:// = arquivo dentro da imagem
                                 # s3://, gs://, hdfs:// = arquivos remotos
  
  sparkVersion: 3.5.3           # Vers√£o do Spark (deve corresponder √† imagem)
```

### Pol√≠ticas de Restart

```yaml
  restartPolicy:
    type: Never                  # Pol√≠tica de restart em caso de falha
                                 # Never: Nunca reinicia automaticamente
                                 # OnFailure: Reinicia apenas em caso de falha
                                 # Always: Sempre reinicia
    
    # Para OnFailure, voc√™ pode configurar:
    # onFailureRetries: 3               # N√∫mero m√°ximo de tentativas
    # onFailureRetryInterval: 10        # Intervalo entre tentativas (segundos)
    # onSubmissionFailureRetries: 5     # Tentativas para falhas de submiss√£o
```

### Configura√ß√µes do Driver

```yaml
  driver:
    cores: 1                     # N√∫mero de CPUs para o driver
                                 # Recomendado: 1-2 cores (driver n√£o processa dados)
    
    memory: 512m                 # Mem√≥ria para o driver
                                 # Formato: 512m, 1g, 2048m
                                 # Inclui overhead do JVM (~10%)
    
    serviceAccount: spark-operator-spark  # ServiceAccount com permiss√µes K8s
                                         # Necess√°rio para criar/gerenciar executors
    
    # Configura√ß√µes opcionais:
    # labels:                    # Labels adicionais para o pod do driver
    #   app: my-spark-app
    # annotations:               # Annotations para o pod
    #   monitoring: enabled
    # tolerations: []            # Tolerations para scheduling
    # nodeSelector: {}           # Sele√ß√£o de n√≥s espec√≠ficos
    # env:                       # Vari√°veis de ambiente
    #   - name: MY_VAR
    #     value: "my-value"
```

### Configura√ß√µes dos Executors

```yaml
  executor:
    cores: 1                     # CPUs por executor
                                 # Recomendado: 2-5 cores por executor
    
    instances: 1                 # N√∫mero de executors
                                 # Depende do tamanho dos dados e recursos dispon√≠veis
    
    memory: 512m                 # Mem√≥ria por executor
                                 # Deve ser suficiente para processamento + cache
    
    # Configura√ß√µes opcionais:
    # labels: {}                 # Labels para pods dos executors
    # annotations: {}            # Annotations
    # tolerations: []            # Tolerations
    # nodeSelector: {}           # Sele√ß√£o de n√≥s
    # env: []                    # Vari√°veis de ambiente
```

### Configura√ß√µes Avan√ßadas (Opcionais)

```yaml
  # Argumentos para a aplica√ß√£o
  arguments:
    - "--input-path"
    - "s3://my-bucket/data"
    - "--output-path" 
    - "s3://my-bucket/results"
  
  # Configura√ß√µes espec√≠ficas do Spark
  sparkConf:
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.adaptive.coalescePartitions.enabled": "true"
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
  
  # JARs de depend√™ncias adicionais
  deps:
    jars:
      - "s3://my-bucket/jars/my-dependency.jar"
    files:
      - "s3://my-bucket/configs/app.conf"
  
  # Configura√ß√µes de volume
  volumes:
    - name: shared-storage
      persistentVolumeClaim:
        claimName: my-pvc
  
  # Monitoramento
  monitoring:
    enabled: true
    prometheus:
      jmxExporterJar: "/opt/spark/jars/jmx_prometheus_javaagent.jar"
```

### üìè Dimensionamento - Regras Pr√°ticas

#### Para Jobs Pequenos (< 1GB dados)
```yaml
driver:
  cores: 1
  memory: 512m
executor:
  cores: 1
  instances: 1-2
  memory: 512m
```

#### Para Jobs M√©dios (1-10GB dados)
```yaml
driver:
  cores: 1
  memory: 1g
executor:
  cores: 2-3
  instances: 2-5
  memory: 2g
```

#### Para Jobs Grandes (> 10GB dados)
```yaml
driver:
  cores: 2
  memory: 2g
executor:
  cores: 3-5
  instances: 5-20
  memory: 4g-8g
```

### üîç Estados do SparkApplication

```bash
# Ver status do job
kubectl get sparkapplication

# Estados poss√≠veis:
# SUBMITTED    - Job foi submetido
# RUNNING      - Job est√° executando  
# COMPLETED    - Job finalizou com sucesso
# FAILED       - Job falhou
# INVALIDATING - Job sendo cancelado
# UNKNOWN      - Estado desconhecido
```

## üõ†Ô∏è Pr√©-requisitos

- Docker
- kubectl
- Kind (Kubernetes in Docker)

## üì¶ Setup do Ambiente

### 1. Instalar Kind com Docker

```bash
# Linux
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Ou via package manager
sudo apt-get update && sudo apt-get install -y kind  # Ubuntu/Debian
brew install kind  # macOS
```

### 2. Criar Cluster Kind

```bash
# Criar cluster
kind create cluster --name spark-cluster

# Verificar se est√° funcionando
kubectl cluster-info --context kind-spark-cluster
```

### 3. Instalar Spark Operator

```bash
# Adicionar reposit√≥rio Helm
helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator

# Atualizar reposit√≥rios
helm repo update

# Instalar Spark Operator
helm install spark-operator spark-operator/spark-operator \
  --namespace spark-operator \
  --create-namespace \
  --set webhook.enable=true

# Verificar instala√ß√£o
kubectl get pods -n spark-operator
```

### 4. Criar ServiceAccount para Spark

```bash
kubectl create serviceaccount spark-operator-spark
kubectl create clusterrolebinding spark-operator-spark \
  --clusterrole=edit \
  --serviceaccount=default:spark-operator-spark
```

## üèóÔ∏è Build e Deploy

### 1. Construir Imagens Docker

```bash
# Imagem da API Launcher
cd launcher
docker build -t gmaas2/spark-launcher:latest .
cd ..

# Imagem dos Jobs Spark
cd jobs
docker build -t gmaas2/spark-astronauts-jobs:latest .
cd ..
```

### 2. Carregar Imagens no Kind

```bash
# Carregar imagens no cluster Kind
kind load docker-image gmaas2/spark-launcher:latest --name spark-cluster
kind load docker-image gmaas2/spark-astronauts-jobs:latest --name spark-cluster
```

### 3. Deploy da API

```bash
# Aplicar manifests da API
kubectl apply -f launcher/k8s/fastapi-spark-launcher.yaml

# Verificar se est√° rodando
kubectl get pods -l app=fastapi-spark-launcher
```

### 4. Expor API Localmente

```bash
# Port-forward para acessar a API
kubectl port-forward svc/fastapi-spark-launcher 8000:80
```

## üß™ Testando

### 1. Testar API

```bash
# Health check
curl http://localhost:8000/health

# Executar job Spark
curl -X POST http://localhost:8000/launch
```

### 2. Verificar Execu√ß√£o do Spark

```bash
# Listar SparkApplications
kubectl get sparkapplication

# Verificar status detalhado
kubectl describe sparkapplication spark-astronauts-YYYYMMDD-HHMMSS

# Ver logs do driver
kubectl logs spark-astronauts-YYYYMMDD-HHMMSS-driver
```

### 3. Monitorar Pods

```bash
# Ver todos os pods
kubectl get pods

# Acompanhar logs em tempo real
kubectl logs -f spark-astronauts-YYYYMMDD-HHMMSS-driver
```

## üìã Comandos √öteis

### Debugging

```bash
# Ver eventos do cluster
kubectl get events --sort-by=.metadata.creationTimestamp

# Descrever pod com problemas
kubectl describe pod <pod-name>

# Ver logs de containers espec√≠ficos
kubectl logs <pod-name> -c <container-name>
```

### Limpeza

```bash
# Deletar SparkApplications antigas
kubectl delete sparkapplication --all

# Deletar API
kubectl delete -f launcher/k8s/fastapi-spark-launcher.yaml

# Deletar cluster Kind
kind delete cluster --name spark-cluster
```

## üîß Desenvolvimento

### Modificando a API

1. Edite os arquivos em `launcher/api/`
2. Reconstrua a imagem: `docker build -t gmaas2/spark-launcher:latest launcher/`
3. Carregue no Kind: `kind load docker-image gmaas2/spark-launcher:latest --name spark-cluster`
4. Reinicie o deployment: `kubectl rollout restart deployment fastapi-spark-launcher`

### Modificando Jobs Spark

1. Edite os arquivos em `jobs/`
2. Reconstrua a imagem: `docker build -t gmaas2/spark-astronauts-jobs:latest jobs/`
3. Carregue no Kind: `kind load docker-image gmaas2/spark-astronauts-jobs:latest --name spark-cluster`
4. Execute um novo job: `curl -X POST http://localhost:8000/launch`

## üìä Exemplo de Sa√≠da

Quando executar o job, voc√™ ver√° algo como:

```bash
$ kubectl logs spark-astronauts-20250803-180000-driver

üë®‚ÄçüöÄ Astronautas no espa√ßo agora:
- Oleg Kononenko (ISS)
- Nikolai Chub (ISS)
- Tracy Caldwell Dyson (ISS)
- Matthew Dominick (ISS)
- Michael Barratt (ISS)
- Jeanette Epps (ISS)
- Alexander Grebenkin (ISS)
- Butch Wilmore (ISS)
- Sunita Williams (ISS)
- Li Guangsu (Tiangong)
- Li Cong (Tiangong)
- Ye Guangfu (Tiangong)
```

## üö® Troubleshooting

### Erro "ImagePullBackOff"
- Verifique se as imagens foram carregadas no Kind: `docker exec -it spark-cluster-control-plane crictl images`

### Erro "CrashLoopBackOff"
- Verifique os logs: `kubectl logs <pod-name>`
- Verifique as depend√™ncias no `requirements.txt`

### API n√£o responde
- Verifique se o port-forward est√° ativo
- Verifique se o pod da API est√° rodando: `kubectl get pods -l app=fastapi-spark-launcher`

## üéØ Pr√≥ximos Passos

- [ ] Adicionar persist√™ncia com PostgreSQL
- [ ] Implementar scheduling com CronJobs
- [ ] Adicionar monitoramento com Prometheus
- [ ] Configurar logs centralizados
- [ ] Implementar testes automatizados 